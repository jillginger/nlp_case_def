{"cells":[{"cell_type":"markdown","source":["#Project objectives\n##To identify keywords(&synonyms) of overactive bladder; using a prediction-based word vectors"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c62de9a6-039a-466d-a6fa-a31d03437744"}}},{"cell_type":"markdown","source":["###Input Format\nWe can't input the raw nurse assessments from the SOAP. Instead, we clean them up by converting everything to txt. \n\n###Input Files\nThe result is to have five documents:\n\ntest-neg.txt: 4 non-OAB nursing assessments from the test data.\ntest-pos.txt: 1 OAB nursing assessments from the test data.\ntrain-neg.txt: 8 negative movie reviews from the training data.\ntrain-pos.txt: 3 positive movie reviews from the training data.\ntrain-unsup.txt: 11 Unlabelled assessments.\n\n###Methods\n\n####I. Subgroups\nThe method I used to define which assessment is positive and which assessment is negative:\n  If there is \"Overactive Bladder\" keyword in the \"Assessment\" row, I put the text from \"Subjective\" row into the \"positive\" group. \n  If there is not \"Overactive Bladder\" keyword in the \"Assessment\" row, I put the text from \"Subjective\" into the \"negative\" group. \n\n####II. Text Cleaning\nThe method I used to clean the text:\n  1. Make all words lowercase\n  2. Eliminate symbols,including \".\", \",\",\"/\",\"\\\",\";\",\":\",\"(\",\")\" and quotations. I kept hyphones.\n  3. Make the text from each PDF one line. Text from different PDFs are in different lines.\n\n####III. NLP Models\nI used word2vec to generate embeddings from text."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e55fe93-4d08-4efd-8820-1d94802d3695"}}},{"cell_type":"markdown","source":["####IV. Modules"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20b6aa6d-8545-40ed-bc1a-17a91d16f16a"}}},{"cell_type":"code","source":["\n# gensim modules\nfrom gensim import utils\nfrom gensim.models.doc2vec import LabeledSentence\nfrom gensim.models import Doc2Vec\n\n# numpy\nimport numpy\n\n# classifier\nfrom sklearn.linear_model import LogisticRegression\n\n# random\nimport random\n\nimport smart_open"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56c6743a-3021-408c-a3b9-43e5515125f2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["class LabeledLineSentence(object):\n    def __init__(self, sources):\n        self.sources = sources\n        \n        flipped = {}\n        \n        # make sure that keys are unique\n        for key, value in sources.items():\n            if value not in flipped:\n                flipped[value] = [key]\n            else:\n                raise Exception('Non-unique prefix encountered')\n    \n    def __iter__(self):\n        for source, prefix in self.sources.items():\n            with utils.smart_open(source) as fin:\n                for item_no, line in enumerate(fin):\n                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n    \n    def to_array(self):\n        self.sentences = []\n        for source, prefix in self.sources.items():\n            with utils.smart_open(source) as fin:\n                for item_no, line in enumerate(fin):\n                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no]))\n        return self.sentences\n    \n    def sentences_perm(self):\n        shuffled = list(self.sentences)\n        random.shuffle(shuffled)\n        return shuffled"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aed9c613-2470-439d-b683-037ff900772a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["sources = {'test-neg.txt':'TEST_NEG', 'test-pos.txt':'TEST_POS', 'train-neg.txt':'TRAIN_NEG', 'train-pos.txt':'TRAIN_POS', 'train-unsup.txt':'TRAIN_UNS'}\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7f259f6-a6d2-4bd9-aa55-6eb808d02bd8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["sentences = LabeledLineSentence(sources)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66839ff2-1ff0-40f8-944b-1a33852c08d3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["model = Doc2Vec(window=5, min_count=1, size=50, sample=1e-5, negative=5, workers=1)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54433686-c92f-45a0-826b-bb8ce124b705"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/python/lib/python3.5/site-packages/gensim/models/doc2vec.py:574: UserWarning: The parameter &#96;size&#96; is deprecated, will be removed in 4.0.0, use &#96;vector_size&#96; instead.\n  warnings.warn(&quot;The parameter &#96;size&#96; is deprecated, will be removed in 4.0.0, use &#96;vector_size&#96; instead.&quot;)\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.5/site-packages/gensim/models/doc2vec.py:574: UserWarning: The parameter &#96;size&#96; is deprecated, will be removed in 4.0.0, use &#96;vector_size&#96; instead.\n  warnings.warn(&quot;The parameter &#96;size&#96; is deprecated, will be removed in 4.0.0, use &#96;vector_size&#96; instead.&quot;)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["model.build_vocab(sentences.to_array())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f71dbc2d-b671-4686-aa9b-3f92cab288cb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3594767104675850&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>model<span class=\"ansiyellow\">.</span>build_vocab<span class=\"ansiyellow\">(</span>sentences<span class=\"ansiyellow\">.</span>to_array<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;command-3594767104675843&gt;</span> in <span class=\"ansicyan\">to_array</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">     21</span>         self<span class=\"ansiyellow\">.</span>sentences <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">[</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     22</span>         <span class=\"ansigreen\">for</span> source<span class=\"ansiyellow\">,</span> prefix <span class=\"ansigreen\">in</span> self<span class=\"ansiyellow\">.</span>sources<span class=\"ansiyellow\">.</span>items<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 23</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">with</span> utils<span class=\"ansiyellow\">.</span>smart_open<span class=\"ansiyellow\">(</span>source<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">as</span> fin<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     24</span>                 <span class=\"ansigreen\">for</span> item_no<span class=\"ansiyellow\">,</span> line <span class=\"ansigreen\">in</span> enumerate<span class=\"ansiyellow\">(</span>fin<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     25</span>                     self<span class=\"ansiyellow\">.</span>sentences<span class=\"ansiyellow\">.</span>append<span class=\"ansiyellow\">(</span>LabeledSentence<span class=\"ansiyellow\">(</span>utils<span class=\"ansiyellow\">.</span>to_unicode<span class=\"ansiyellow\">(</span>line<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">[</span>prefix <span class=\"ansiyellow\">+</span> <span class=\"ansiblue\">&apos;_%s&apos;</span> <span class=\"ansiyellow\">%</span> item_no<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: module &apos;gensim.utils&apos; has no attribute &apos;smart_open&apos;</div>","errorSummary":"<span class=\"ansired\">AttributeError</span>: module &apos;gensim.utils&apos; has no attribute &apos;smart_open&apos;","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3594767104675850&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>model<span class=\"ansiyellow\">.</span>build_vocab<span class=\"ansiyellow\">(</span>sentences<span class=\"ansiyellow\">.</span>to_array<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;command-3594767104675843&gt;</span> in <span class=\"ansicyan\">to_array</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">     21</span>         self<span class=\"ansiyellow\">.</span>sentences <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">[</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     22</span>         <span class=\"ansigreen\">for</span> source<span class=\"ansiyellow\">,</span> prefix <span class=\"ansigreen\">in</span> self<span class=\"ansiyellow\">.</span>sources<span class=\"ansiyellow\">.</span>items<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 23</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">with</span> utils<span class=\"ansiyellow\">.</span>smart_open<span class=\"ansiyellow\">(</span>source<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">as</span> fin<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     24</span>                 <span class=\"ansigreen\">for</span> item_no<span class=\"ansiyellow\">,</span> line <span class=\"ansigreen\">in</span> enumerate<span class=\"ansiyellow\">(</span>fin<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     25</span>                     self<span class=\"ansiyellow\">.</span>sentences<span class=\"ansiyellow\">.</span>append<span class=\"ansiyellow\">(</span>LabeledSentence<span class=\"ansiyellow\">(</span>utils<span class=\"ansiyellow\">.</span>to_unicode<span class=\"ansiyellow\">(</span>line<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">[</span>prefix <span class=\"ansiyellow\">+</span> <span class=\"ansiblue\">&apos;_%s&apos;</span> <span class=\"ansiyellow\">%</span> item_no<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: module &apos;gensim.utils&apos; has no attribute &apos;smart_open&apos;</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["####V.Training Doc2vec"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"458c01d2-85aa-4add-8ed9-571221427104"}}},{"cell_type":"code","source":["for epoch in range(10):\n    model.train(sentences.sentences_perm())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ba13a7e-0c7c-4618-abe6-650ce177a6a7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">RuntimeError</span>                              Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3594767104675852&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansigreen\">for</span> epoch <span class=\"ansigreen\">in</span> range<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">10</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\">     </span>model<span class=\"ansiyellow\">.</span>train<span class=\"ansiyellow\">(</span>sentences<span class=\"ansiyellow\">.</span>sentences_perm<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/gensim/models/doc2vec.py</span> in <span class=\"ansicyan\">train</span><span class=\"ansiblue\">(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)</span>\n<span class=\"ansigreen\">    811</span>             sentences<span class=\"ansiyellow\">=</span>documents<span class=\"ansiyellow\">,</span> corpus_file<span class=\"ansiyellow\">=</span>corpus_file<span class=\"ansiyellow\">,</span> total_examples<span class=\"ansiyellow\">=</span>total_examples<span class=\"ansiyellow\">,</span> total_words<span class=\"ansiyellow\">=</span>total_words<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    812</span>             epochs<span class=\"ansiyellow\">=</span>epochs<span class=\"ansiyellow\">,</span> start_alpha<span class=\"ansiyellow\">=</span>start_alpha<span class=\"ansiyellow\">,</span> end_alpha<span class=\"ansiyellow\">=</span>end_alpha<span class=\"ansiyellow\">,</span> word_count<span class=\"ansiyellow\">=</span>word_count<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 813</span><span class=\"ansiyellow\">             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks, **kwargs)\n</span><span class=\"ansigreen\">    814</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    815</span>     <span class=\"ansiyellow\">@</span>classmethod<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/gensim/models/base_any2vec.py</span> in <span class=\"ansicyan\">train</span><span class=\"ansiblue\">(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)</span>\n<span class=\"ansigreen\">   1079</span>             total_words<span class=\"ansiyellow\">=</span>total_words<span class=\"ansiyellow\">,</span> epochs<span class=\"ansiyellow\">=</span>epochs<span class=\"ansiyellow\">,</span> start_alpha<span class=\"ansiyellow\">=</span>start_alpha<span class=\"ansiyellow\">,</span> end_alpha<span class=\"ansiyellow\">=</span>end_alpha<span class=\"ansiyellow\">,</span> word_count<span class=\"ansiyellow\">=</span>word_count<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1080</span>             queue_factor<span class=\"ansiyellow\">=</span>queue_factor<span class=\"ansiyellow\">,</span> report_delay<span class=\"ansiyellow\">=</span>report_delay<span class=\"ansiyellow\">,</span> compute_loss<span class=\"ansiyellow\">=</span>compute_loss<span class=\"ansiyellow\">,</span> callbacks<span class=\"ansiyellow\">=</span>callbacks<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1081</span><span class=\"ansiyellow\">             **kwargs)\n</span><span class=\"ansigreen\">   1082</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1083</span>     <span class=\"ansigreen\">def</span> _get_job_params<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> cur_epoch<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/gensim/models/base_any2vec.py</span> in <span class=\"ansicyan\">train</span><span class=\"ansiblue\">(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)</span>\n<span class=\"ansigreen\">    534</span>             epochs<span class=\"ansiyellow\">=</span>epochs<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    535</span>             total_examples<span class=\"ansiyellow\">=</span>total_examples<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 536</span><span class=\"ansiyellow\">             total_words=total_words, **kwargs)\n</span><span class=\"ansigreen\">    537</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    538</span>         <span class=\"ansigreen\">for</span> callback <span class=\"ansigreen\">in</span> self<span class=\"ansiyellow\">.</span>callbacks<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/gensim/models/base_any2vec.py</span> in <span class=\"ansicyan\">_check_training_sanity</span><span class=\"ansiblue\">(self, epochs, total_examples, total_words, **kwargs)</span>\n<span class=\"ansigreen\">   1185</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1186</span>         <span class=\"ansigreen\">if</span> <span class=\"ansigreen\">not</span> self<span class=\"ansiyellow\">.</span>wv<span class=\"ansiyellow\">.</span>vocab<span class=\"ansiyellow\">:</span>  <span class=\"ansired\"># should be set by &#96;build_vocab&#96;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1187</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> RuntimeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;you must first build vocabulary before training the model&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1188</span>         <span class=\"ansigreen\">if</span> <span class=\"ansigreen\">not</span> len<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>wv<span class=\"ansiyellow\">.</span>vectors<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1189</span>             <span class=\"ansigreen\">raise</span> RuntimeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;you must initialize vectors before training the model&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">RuntimeError</span>: you must first build vocabulary before training the model</div>","errorSummary":"<span class=\"ansired\">RuntimeError</span>: you must first build vocabulary before training the model","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">RuntimeError</span>                              Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3594767104675852&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansigreen\">for</span> epoch <span class=\"ansigreen\">in</span> range<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">10</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\">     </span>model<span class=\"ansiyellow\">.</span>train<span class=\"ansiyellow\">(</span>sentences<span class=\"ansiyellow\">.</span>sentences_perm<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/gensim/models/doc2vec.py</span> in <span class=\"ansicyan\">train</span><span class=\"ansiblue\">(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)</span>\n<span class=\"ansigreen\">    811</span>             sentences<span class=\"ansiyellow\">=</span>documents<span class=\"ansiyellow\">,</span> corpus_file<span class=\"ansiyellow\">=</span>corpus_file<span class=\"ansiyellow\">,</span> total_examples<span class=\"ansiyellow\">=</span>total_examples<span class=\"ansiyellow\">,</span> total_words<span class=\"ansiyellow\">=</span>total_words<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    812</span>             epochs<span class=\"ansiyellow\">=</span>epochs<span class=\"ansiyellow\">,</span> start_alpha<span class=\"ansiyellow\">=</span>start_alpha<span class=\"ansiyellow\">,</span> end_alpha<span class=\"ansiyellow\">=</span>end_alpha<span class=\"ansiyellow\">,</span> word_count<span class=\"ansiyellow\">=</span>word_count<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 813</span><span class=\"ansiyellow\">             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks, **kwargs)\n</span><span class=\"ansigreen\">    814</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    815</span>     <span class=\"ansiyellow\">@</span>classmethod<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/gensim/models/base_any2vec.py</span> in <span class=\"ansicyan\">train</span><span class=\"ansiblue\">(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)</span>\n<span class=\"ansigreen\">   1079</span>             total_words<span class=\"ansiyellow\">=</span>total_words<span class=\"ansiyellow\">,</span> epochs<span class=\"ansiyellow\">=</span>epochs<span class=\"ansiyellow\">,</span> start_alpha<span class=\"ansiyellow\">=</span>start_alpha<span class=\"ansiyellow\">,</span> end_alpha<span class=\"ansiyellow\">=</span>end_alpha<span class=\"ansiyellow\">,</span> word_count<span class=\"ansiyellow\">=</span>word_count<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1080</span>             queue_factor<span class=\"ansiyellow\">=</span>queue_factor<span class=\"ansiyellow\">,</span> report_delay<span class=\"ansiyellow\">=</span>report_delay<span class=\"ansiyellow\">,</span> compute_loss<span class=\"ansiyellow\">=</span>compute_loss<span class=\"ansiyellow\">,</span> callbacks<span class=\"ansiyellow\">=</span>callbacks<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1081</span><span class=\"ansiyellow\">             **kwargs)\n</span><span class=\"ansigreen\">   1082</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1083</span>     <span class=\"ansigreen\">def</span> _get_job_params<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> cur_epoch<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/gensim/models/base_any2vec.py</span> in <span class=\"ansicyan\">train</span><span class=\"ansiblue\">(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)</span>\n<span class=\"ansigreen\">    534</span>             epochs<span class=\"ansiyellow\">=</span>epochs<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    535</span>             total_examples<span class=\"ansiyellow\">=</span>total_examples<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 536</span><span class=\"ansiyellow\">             total_words=total_words, **kwargs)\n</span><span class=\"ansigreen\">    537</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    538</span>         <span class=\"ansigreen\">for</span> callback <span class=\"ansigreen\">in</span> self<span class=\"ansiyellow\">.</span>callbacks<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/gensim/models/base_any2vec.py</span> in <span class=\"ansicyan\">_check_training_sanity</span><span class=\"ansiblue\">(self, epochs, total_examples, total_words, **kwargs)</span>\n<span class=\"ansigreen\">   1185</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1186</span>         <span class=\"ansigreen\">if</span> <span class=\"ansigreen\">not</span> self<span class=\"ansiyellow\">.</span>wv<span class=\"ansiyellow\">.</span>vocab<span class=\"ansiyellow\">:</span>  <span class=\"ansired\"># should be set by &#96;build_vocab&#96;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1187</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> RuntimeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;you must first build vocabulary before training the model&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1188</span>         <span class=\"ansigreen\">if</span> <span class=\"ansigreen\">not</span> len<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>wv<span class=\"ansiyellow\">.</span>vectors<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1189</span>             <span class=\"ansigreen\">raise</span> RuntimeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;you must initialize vectors before training the model&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">RuntimeError</span>: you must first build vocabulary before training the model</div>"]}}],"execution_count":0},{"cell_type":"code","source":["model.most_similar('overactive')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e4471cd-5da3-451f-bc73-7760ff1411e1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["model['TRAIN_NEG_0']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13e7a7bb-323a-4151-9852-bec14e524055"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["model.save('~/Google Drive/2019 Surgical Outcome/OAB Definition/nlp/txt/soap.d2v')\nmodel = Doc2Vec.load('~/Google Drive/2019 Surgical Outcome/OAB Definition/nlp/txt/soap.d2v')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a83cc919-8cf8-4a09-b9eb-846907f9370e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["####VI. Classifying sentiment"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19c48e1e-9c11-46b3-bc05-a35d430429ae"}}},{"cell_type":"code","source":["train_arrays = numpy.zeros((11, 100))\ntrain_labels = numpy.zeros(11)\n\nfor i in range(3):\n    prefix_train_pos = 'TRAIN_POS_' + str(i)\n    prefix_train_neg = 'TRAIN_NEG_' + str(i)\n    train_arrays[i] = model[prefix_train_pos]\n    train_arrays[3 + i] = model[prefix_train_neg]\n    train_labels[i] = 1\n    train_labels[3 + i] = 0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a653f118-209f-4e10-8729-7970010e71b9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print train_arrays"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e385b7c-4c60-46ac-8cb4-d7cfa8985a27"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print train_labels"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf5aac78-60ab-447e-89c8-c6b2f469eff3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\ntest_arrays = numpy.zeros((11, 100))\ntest_labels = numpy.zeros(11)\n\nfor i in range(1):\n    prefix_test_pos = 'TEST_POS_' + str(i)\n    prefix_test_neg = 'TEST_NEG_' + str(i)\n    test_arrays[i] = model[prefix_test_pos]\n    test_arrays[1 + i] = model[prefix_test_neg]\n    test_labels[i] = 1\n    test_labels[1 + i] = 0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6b79572-b936-4fa3-a729-6df4c6054980"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["classifier = LogisticRegression()\nclassifier.fit(train_arrays, train_labels)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cfa03378-58ef-43e4-9b50-6c5a5b7ad20d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["classifier.score(test_arrays, test_labels)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9eb7fba7-fbcd-4a8e-9859-bc5128e6d87b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["####VI. Current Problems\n1. code error with smart_open\n2. some nurses use abbreviations (exp. \"f/u\", \"appmnt\"...) in assessments and some are not. It'd be better if I got a list of what abbreviations represent what.\n3. typos are not corrected in the current version\n4. The process of getting SOAP notes and dividing SOAP notes into OAB & non-OAB group is not automated."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3be096da-c647-45e4-93e9-a9016686e950"}}},{"cell_type":"markdown","source":["####VII. The advantages of the current method \n1. Converted words to embedddings, so it's faster to calculate\n2. Not only keyword importance was recognized, but also joint probabilities of two, three, four or more words appearing close to each other.\n3. Databricks support multiple clusters to do parallel computing. So a huge dataset won't be a big problem."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"588585c0-83ff-410e-87d5-3c65b519ff3e"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"nlp","dashboards":[],"language":"python","widgets":{},"notebookOrigID":2340533581108777}},"nbformat":4,"nbformat_minor":0}
